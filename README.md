# Multi-Class-Classification-of-Tweets
Tweets Classification on Different Topics
Evaluation & Discussion
The experiments were conducted in a systematic way of assessing the performance of each model that was evaluated on the Twitter topic classification task. The methodology used in the evaluation comprises several crucial stages: data partitioning, model training, hyperparameter optimization, and performance evaluation against appropriate metrics.
Interpretation of Results
From the figures the confusion matrices indicate how correctly the six models have classified the tweets. The classification will be based on the six outlined in sports & gaming, pop culture, daily life, business & entrepreneurs, science & technology, or arts & culture. To represent such categorization for visual interpretation of the result of classification, each cell in the confusion matrix represents the number of instances that have been classified into a specific category.
The accuracy, precision, recall, and F1-score performance metrics in the figures for three different models: Logistic Regression, K-Nearest Neighbors (KNN), and Gradient Boosting. These metrics, in turn, will give an inference based on their result, which model among the three will best suit to classify the tweets among six distinct categories.
The Logistic Regression model was at the top, against the overall correctness of the predictions, with an accuracy of about 78.43% among other models. However, its precision, recall, and f1-score metrics point out some dissimilar performances within some particular classes. It showed good precision in some topics—sports & gaming—while it struggles with others, e.g., daily life and business & entrepreneurs. 
Although both precision and recall for Gradient Boosting were lower than that achieved by Logistic Regression, it still managed to hold a similar level on both scores, which might be an indicator of strong performance that covers multiple categories. Hence, while comparing model performances, trade-offs will be shown against accuracy with precision, recall, and F1 score. Logistic Regression has been observed to have the highest accuracy, though its performance was relatively varying significantly across different classes, therefore possibly struggling to conduct proper classification of tweets into different categories in some cases.
Discussion of Findings
Analyzing the results, it can be said that different levels of performance were shown against different classes by individual models. For example, the Logistic Regression model appeared fairly accurate and precise for sports & gaming, but the classes of daily life and business & entrepreneurs showed the worst performance. This is due to the fact that the results from the model were equally competitive for some classes of poor performance, suggesting challenges specific to those classes. Out of the 3 scenarios, regex with stemming preprocessing shows the better results in terms of all metrices.
Gradient Boosting showed the best consistency of the results across all the three classes, which had relatively high values for precision and accuracy. This, therefore, may mean that in regard to choosing the model to be used in classifying the topics in Twitter data, Gradient Boosting may be the best model as it portrays good performance even in the presence of different categories.
Conclusion
Finally, this work attempted to come up with a solid pipeline for classifying the topic of Twitter, led by the CRISP-DM methodology. There are 3 scenarios performed: regex, regex with lemmatization and regex with stemming. Regex with stemming out performed among all. Several models and techniques were tried, including logistic regression, k-nearest neighbors, and gradient boosting. We measured these classifiers with accuracy, precision, recall, and F1-score. Ensembling methods and new feature engineering, although it achieves the highest accuracy, still need to be explored for their potential development. The results give evidence of a role for methodological strictness and iterative development in the NLP pipeline development.
Future Work 
Based on the results of the experiments and the conclusions drawn, some future research along several avenues of the classification of Twitter topics can be conducted. Exploring the direction, for instance, with stacking or blending ensemble methods could most probably be very promising. Ensemble methods predict with a combination of different base model predictions in order to improve the overall performance of the model. It has been brought into consideration that the various methods which help in ensemble models, through which the strength and weaknesses of different models can be balanced and mitigated, might assist in achieving better accuracy or more robust classification performances against the diverse tweet categories. It further encourages in this way by the fact that the Gradient Boosting model, though less performant in overall accuracy compared to the Logistic Regression model, shows better stability of classifier performance across classes. 

